{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "906f6456",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4d956df4",
   "metadata": {},
   "source": [
    "Import or install the following packages if you do not have them installed already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d38562f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#required packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import rasterstats\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import scipy.sparse as sparse\n",
    "import patoolib\n",
    "from osgeo import gdal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697f482d",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ecdc96",
   "metadata": {},
   "source": [
    "This script downloads daily rainfall rasters from CHIRPS (https://www.chc.ucsb.edu/data/chirps), unzips and clips the rasters to the desired study area and the extract point timeseries for multiple stations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c689c5b3",
   "metadata": {},
   "source": [
    "### First!! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d262be",
   "metadata": {},
   "source": [
    "Create folders to save the downloaded data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbd5ee6",
   "metadata": {},
   "source": [
    "### Download the raw tiff files "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ddab49",
   "metadata": {},
   "source": [
    "The files are available from this url:https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p05/. Each folder contains daily data for each year. Each TIFF file contains data for the entire African continent.\n",
    "Recommended: First explore the data to understand the format and contents. You can manually download one file to compare it with the output of the code\n",
    "\n",
    "Summary of the code:\n",
    "First generate list of days in a month and months in a years\n",
    "The format of the data is 'chirps-v2.0.1981.01.01.tif.gz' so we'll need to generate a list of numbers where the number between 1 and 9 are preceded by a zero i.e 01,02,03, etc. We'll call these days two_sf_days i.e 2 significant figures days\n",
    "we will also follow the same procedure for months. Iterate throught url and extract daily zipped tiff files\n",
    "\n",
    "Dont forget to delete downloaded files which do not exist e.g the code assumes all months have 31 days and will for example download data for 31st February which does not exists. You can identify these files by their size. They will mostly have a 1KB size. Delete these files before unzipping the TIFFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a358e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'H:\\CHIRPS_data\\afr_daily') #path to zipped tiff files\n",
    "\n",
    "#generate list of days in 2 significant figures\n",
    "two_sf_days=[] #empty list to store the days\n",
    "days=list(np.arange(1,32)) #generate 1 to 31 days\n",
    "for day in days:\n",
    "          day_dd=(\"%02d\" % (day,))\n",
    "          two_sf_days.append(day_dd) \n",
    "\n",
    "#generate list of days in 2 significant figures\n",
    "two_sf_months=[] #empty list to store months\n",
    "months=list(np.arange(1,13)) #generates 12 months\n",
    "for mon in months:\n",
    "          month_mm=(\"%02d\" % (mon,))\n",
    "          two_sf_months.append(month_mm)\n",
    "\n",
    "#generate list of years from 1981-2022 . np.arange is end exclusive so 2023 will not be included\n",
    "years=list(np.arange(1981,2023))\n",
    "\n",
    "#iterate through the folders and extract the daily data\n",
    "for yr in years:\n",
    "    for month in two_sf_months:\n",
    "        for day in two_sf_days:\n",
    "            url='https://data.chc.ucsb.edu/products/CHIRPS-2.0/africa_daily/tifs/p05/'+ str(yr) + '/' + 'chirps-v2.0.'+str(yr)+ '.'+ str(month) + '.'+ str(day) + '.tif.gz'\n",
    "            r=requests.get(url, stream=True)      \n",
    "            open('chirps_'+str(yr)+'_' + str(month)+'_'+str(day)+'.gz', 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd57493",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Unzip the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51db35ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate through the zipped files and unzip and save to unzipped folder. Make sure you change the file path\n",
    "for zipfile in os.listdir(r'H:\\CHIRPS_data\\afr_daily'):\n",
    "    #print(zipfiles)\n",
    "    if zipfile[-3:]=='.gz':\n",
    "        patoolib.extract_archive(zipfile, outdir=r'H:\\CHIRPS_data\\afr_daily')\n",
    "        \n",
    "#optional\n",
    "#add file extensions\n",
    "#for unzipped_file in os.listdir(r'H:\\CHIRPS_data\\unzipped_files'):\n",
    "    #os.chdir(r'H:\\CHIRPS_data\\unzipped_files')\n",
    "    #os.rename(unzipped_file, unzipped_file)# +'.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5022f1a3",
   "metadata": {},
   "source": [
    "### Clip the raster to catchment area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6847e6",
   "metadata": {},
   "source": [
    "This helps to reduce memory committed to processing the files.\n",
    "If the catchment is small, clip the raster files using a bigger shapefile e.g the boundaries of a country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9deb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "define paths to zipped files and the output path where unzipped files will be saved\n",
    "input_path=r'H:\\CHIRPS_data\\afr_daily' #change paths to folders accordingly\n",
    "output_path=r'H:\\CHIRPS_data\\EA_rasters'\n",
    "        \n",
    "#define path to shapefile\n",
    "shapefile=r\"H:\\CHIRPS_data\\EA_Clip.shp\"\n",
    "\n",
    "raster_list = [raster for raster in os.listdir(input_path) if raster[-4:]=='.tif']\n",
    "\n",
    "#clip all the selected raster files with the Warp option from GDAL\n",
    "for raster in raster_list:\n",
    "    print(output_path)\n",
    "    options = gdal.WarpOptions(cutlineDSName=shapefile,cropToCutline=True)\n",
    "    outBand = gdal.Warp(srcDSOrSrcDSTab=os.path.join(input_path, raster),\n",
    "                        destNameOrDestDS=os.path.join(output_path, raster[:-4]+raster[-4:]),\n",
    "                        options=options)\n",
    "    outraster= None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f722cd3",
   "metadata": {},
   "source": [
    "### Extract station data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b21d34",
   "metadata": {},
   "source": [
    "For point data extraction, create a shapefile containing the name, lat and lon of your stations. \n",
    "The lat/lon should be in decimal degree. This video instructs how to import point from data from Excel and convert to shapefile https://www.youtube.com/watch?v=Xgi-UdyDi1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73546367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty pandas dataframe called 'table'\n",
    "table = pd.DataFrame(index = np.arange(0,1))\n",
    "\n",
    "#First create a shapefile of points stations \n",
    "#Read the points shapefile using GeoPandas \n",
    "stations = gpd.read_file(r'H:\\CHIRPS_data\\unzipped_files\\chirps_stations.shp')\n",
    "stations['lon'] = stations['geometry'].x\n",
    "stations['lat'] = stations['geometry'].y\n",
    "\n",
    "Matrix = pd.DataFrame()\n",
    "\n",
    "# Iterate through the rasters and save the data as individual arrays to a Matrix \n",
    "for files in os.listdir(r'H:\\CHIRPS_data\\EA_rasters''):\n",
    "    if files[-4: ] == '.tif':\n",
    "        dataset = rasterio.open(r'H:\\CHIRPS_data\\EA_rasters'+'\\\\'+files)\n",
    "        data_array = dataset.read(1)\n",
    "        data_array_sparse = sparse.coo_matrix(data_array, shape = (1600,1500))\n",
    "        data = files[ :-4]\n",
    "        Matrix[data] = data_array_sparse.toarray().tolist()\n",
    "        print('Processing is done for the raster: '+ files[:-4])\n",
    "\n",
    "# Iterate through the stations and get the corresponding row and column for the related x, y coordinates    \n",
    "for index, row in stations.iterrows():\n",
    "        station_name = str(row['station_na'])#station_na refers to the station name in the stations shapefile\n",
    "        lon = float(row['lon'])\n",
    "        lat = float(row['lat'])\n",
    "        x,y = (lon, lat)\n",
    "        row, col = dataset.index(x, y)\n",
    "        print('Processing: '+ station_name)\n",
    "        \n",
    "        # Pick the rainfall value from each stored raster array and record it into the previously created 'table'\n",
    "        for records_date in Matrix.columns.tolist():\n",
    "            a = Matrix[records_date]\n",
    "            rf_value = a.loc[int(row)][int(col)]\n",
    "            table[records_date] = rf_value\n",
    "            transpose_mat = table.T\n",
    "            transpose_mat.rename(columns = {0: 'Rainfall(mm)'}, inplace = True)\n",
    "        \n",
    "            transpose_mat.to_csv(r'H:\\CHIRPS_data\\EA_rasters'+'\\\\'+station_name+'.txt') #provide path to station data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
